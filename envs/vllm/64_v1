#!/bin/bash

MODEL_PATH=""
VLLM_IMAGE=""

QUANTIZATION="auto"
KV_CACHE_DTYPE="auto"

# VLLM control environment variables
VLLM_USE_TRITON_FLASH_ATTN=0
VLLM_V1_USE_PREFILL_DECODE_ATTENTION=1
VLLM_ROCM_USE_AITER=1
VLLM_ROCM_USE_AITER_MHA=0
VLLM_ROCM_USE_AITER_RMSNORM=0
VLLM_WORKER_MULTIPROC_METHOD=spawn
SAFETENSORS_FAST_GPU=1
OMP_NUM_THREADS=128
NCCL_MIN_NCHANNELS=112
HIP_FORCE_DEV_KERNARG=1
TORCH_BLAS_PREFER_HIPBLASLT=1
PYTORCH_TUNABLEOP_ENABLED=1
PYTORCH_TUNABLEOP_TUNING=0

# Request Settings
MAX_NUM_SEQS=128
REQUEST_RATE=inf
NUM_ITERATION=8

# Parallelism Settings
TENSOR_PARALLEL_SIZE=1
PIPELINE_PARALLEL_SIZE=1

# Server Arguments
GPU_MEMORY_UTILIZATION=0.9

# Model Stored Path
HF_HOME=${HOME}/models
