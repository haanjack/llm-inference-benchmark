# Evaluation dependencies for LLM Inference Benchmark
# Install with: pip install -r requirements-evaluation.txt

# LM Evaluation Harness - for running evaluation tasks
lm-eval[api]>=0.4.0

# Optional: Additional evaluation frameworks (uncomment if needed)
# opencompass>=0.2.0
# helm>=0.3.0
